# 机器学习

## 一般步骤

1. 数据收集和预处理：收集与问题相关的数据，并进行预处理。这可能包括数据清洗、去除异常值、处理缺失数据、特征选择和特征转换等操作。
2. 数据划分：将数据集划分为训练集、验证集和测试集。训练集用于模型的参数估计和优化，验证集用于调整模型的超参数和评估模型的性能，测试集用于最终评估模型的泛化性能。
3. 特征工程：根据问题的需求和数据的特点，进行特征工程。这可能包括特征提取、特征变换、特征缩放、特征组合等操作，以提取有用的特征表示。
4. 模型选择和构建：选择适合问题的机器学习算法或模型，并构建模型。常见的模型包括线性回归、决策树、支持向量机、神经网络等。
5. 模型训练：使用训练集中的样本对模型进行训练。训练的目标是通过调整模型的参数使其在训练数据上达到最佳拟合。
6. 模型评估：使用验证集评估模型在未见过的数据上的性能。常见的评估指标包括准确率、精确率、召回率、F1分数等。
7. 模型调优：根据验证集的评估结果，调整模型的超参数、模型结构或其他配置，以提升模型的泛化性能。
8. 模型测试和部署：使用测试集评估最终模型的性能。如果模型达到预期的性能要求，将其部署到实际应用中。
9. 模型监控和维护：定期监控模型的性能，并根据实际应用情况对模型进行维护和更新。

## 训练过程

1. 正向传播（Forward Propagation）：使用当前模型参数，将输入数据通过模型前向传播，计算输出值。
2. 计算损失（Compute Loss）：将模型的输出与真实标签进行比较，计算损失或误差。损失函数衡量了模型预测结果与真实值之间的差异。
3. 反向传播（Backward Propagation）：通过反向传播算法，计算损失函数对模型参数的梯度。梯度表示了损失函数对参数的变化敏感程度。
4. 参数更新（Parameter Update）：使用梯度下降法或其他优化算法，根据梯度的方向和大小来更新模型的参数。梯度下降法的基本思想是沿着梯度的反方向，以一定的学习率调整参数的取值，使损失函数逐渐减小。
5. 重复迭代：重复执行上述步骤，直到达到预定义的停止条件，如达到一定的迭代次数或损失函数收敛。

## 梯度下降

梯度下降是一种优化算法，用于更新模型参数以最小化损失函数。在每次迭代中，梯度下降算法根据损失函数对参数的梯度信息，调整参数的取值，使损失函数逐渐减小。梯度表示了损失函数在参数空间中的变化率，梯度下降算法利用这一信息来指导参数更新的方向和步长。

具体而言，梯度下降算法有不同的变体，包括批量梯度下降（Batch Gradient Descent）、随机梯度下降（Stochastic Gradient Descent）和小批量梯度下降（Mini-Batch Gradient Descent）。这些变体在每次迭代中使用不同的样本数量来计算梯度，并更新模型参数。

总之，模型训练时，每次迭代需要更新模型的参数，梯度下降是一种常用的优化算法，用于根据损失函数的梯度信息来调整参数的取值，以逐步优化模型的性能。

# 深度学习

## 过拟合问题

神经网络容易过拟合，加入正则化机制 $R(W)$, 或者 `drop-out`

**`drop-out`**

+ 每一次训练过程中，随机杀死一些神经元

## 激励(活)函数

激活函数在神经网络中扮演着非线性变换的角色，将神经元的输入映射到输出。它们的作用是引入非线性性质，使得神经网络能够学习和表示更加复杂的函数关系。

softmax：权重参数过大或过小，梯度为0
$$
\sigma(x) = \frac{1}{1+e^{-x}}
$$


relu：目前基本上都用这个
$$
\sigma(x) = max(0,x)
$$


## 常见深度学习算法

以下是一些主流的深度学习算法：
$$
y = xw + b
$$


### 卷积神经网络

卷积神经网络（Convolutional Neural Networks，CNN）：CNN是一种广泛应用于计算机视觉领域的深度学习算法。它通过卷积层、池化层和全连接层等组件来自动学习图像和特征的表示，并在图像分类、目标检测、图像分割等任务中取得了出色的表现。

+ 整体架构
    + 输入层
    + 卷积层
    + 池化层
    + 全连接层
+ 池化
    + 下采样，例如最大池化：选取一块区域，保留最重要的数（最大的数）

+ 卷积后输出尺寸大小

    + $$
        O_H = \frac{H+2p-F_H}{S} + 1  
        \\
        O_W = \frac{H+2p-F_W}{S} + 1
        $$

    
    + 其中p表示填充数，S表示步长
    
+ 



### 循环神经网络

循环神经网络（Recurrent Neural Networks，RNN）：RNN是一种能够处理序列数据的深度学习算法。它具有记忆能力，通过在网络中引入循环连接，可以处理变长的序列输入。RNN在自然语言处理、语音识别、机器翻译等任务中表现出色。

### 长短期记忆网络

长短期记忆网络（Long Short-Term Memory，LSTM）：LSTM是一种特殊类型的RNN，通过引入门控机制来解决传统RNN中的梯度消失和梯度爆炸问题。LSTM在处理长序列和捕捉长期依赖关系方面表现出色，广泛应用于语言模型、文本生成和语音识别等任务。

### 生成对抗网络

生成对抗网络（Generative Adversarial Networks，GAN）：GAN是一种由生成器和判别器组成的对抗性模型。生成器试图生成逼真的样本，而判别器则试图区分真实样本和生成样本。通过对抗训练，GAN可以生成逼真的图像、音频、文本等，并在图像生成、图像转换等任务中取得了重要的突破。

### 强化学习

强化学习（Reinforcement Learning，RL）：RL是一种通过智能体与环境的交互学习来制定决策的学习框架。强化学习通过试错和奖励机制来优化策略，从而使智能体能够在复杂环境中学习和决策。RL在游戏、机器人控制和推荐系统等领域取得了显著的成果。

除了上述算法，还有许多其他的深度学习算法被广泛应用于不同领域的问题，如注意力机制（Attention）、变分自编码器（Variational Autoencoders，VAE）、Transformer等。这些算法在不同的任务和数据类型下展现了强大的能力，并推动了深度学习在各个领域的发展。



## Transformer

Transformer是一种用于自然语言处理（NLP）任务的深度学习模型，首次提出于2017年的论文"Attention Is All You Need"。它的设计目标是解决传统的循环神经网络（RNN）在处理长序列时存在的计算效率和并行性问题。

Transformer模型基于自注意力机制（Self-Attention）和位置编码（Positional Encoding），它摒弃了传统的循环或卷积操作，完全基于注意力机制来实现序列建模。

关键组件：

1. 自注意力机制（Self-Attention）：自注意力机制是Transformer的核心组件。它通过计算输入序列中不同位置之间的关联度来获取每个位置的表示。自注意力机制允许模型在输入序列的不同位置之间建立关联，从而更好地捕捉上下文信息。
2. 位置编码（Positional Encoding）：由于Transformer没有使用循环或卷积操作，它无法捕捉到序列元素的顺序信息。为了解决这个问题，Transformer引入了位置编码，将每个位置的信息嵌入到输入的表示中。位置编码是通过一系列特殊的向量来表示序列中每个位置的信息，从而将序列的顺序信息融入模型中。
3. 多头注意力机制（Multi-Head Attention）：为了提高模型的表示能力，Transformer引入了多头注意力机制。多头注意力机制通过将注意力机制应用于多个子空间中的不同投影，从而允许模型在不同的表示空间中学习到不同类型的注意力。
4. 前馈神经网络（Feed-Forward Neural Network）：Transformer中的每个注意力子层后面都连接着一个前馈神经网络，它用于对注意力子层的输出进行非线性变换。前馈神经网络通常由两个全连接层和一个激活函数组成。

优势与应用：

Transformer模型在自然语言处理任务中取得了显著的成果，尤其在机器翻译任务中表现出色。相比于传统的循环神经网络，Transformer具有以下优势：

1. 并行计算：由于自注意力机制的并行性质，Transformer可以高效地进行并行计算，加快训练和推理的速度。
2. 长期依赖建模：Transformer能够捕捉到序列中的长期依赖关系，而传统的循环神经网络在处理长序列时容易出现梯度消失或梯度爆炸问题。
3. 全局信息获取：自注意力机制允许模型在每个位置上对整个输入序列进行注意力计算，从而能够获取全局的上下文信息。

除了机器翻译任务，Transformer还被广泛应用于语言建模、文本分类、命名实体识别、语义解析等自然语言处理任务，并在这些任务中取得了优秀的性能。此外，Transformer的思想也被应用于计算机视觉任务，如图像生成和目标检测等领域。











# 人脸识别

## 论文一：5-1.The Elements of End-to-end Deep Face Recognition A Survey of Recent Advances（端到端深度人脸识别原理：最新进展综述）

### 人脸识别组成

1. 人脸检测
2. 人脸对齐
3. 人脸表示

#### 人脸检测

​		在深度学习时代之前，人脸检测的开创性工作之一是Viola Jones[230]人脸检测器，它利用具有Haar特征的AdaBoost分类器来构建级联结构。

​		人脸检测人脸检测是人脸识别系统的第一步。在给定输入图像的情况下，人脸检测的目的是找到图像中的所有人脸，并给出具有置信度分数的边界框坐标。人脸检测的主要挑战包括不同的分辨率、尺度、姿态、照明、遮挡等。

​		为了呈现清晰分类的深度人脸检测方法，我们将其分为七组，即多阶段、单阶段、基于锚、无锚、多任务学习、CPU实时和面向问题的方法

​		多阶段方法。遵循从粗到细的方式或细化策略的建议，基于多阶段的检测器首先生成多个候选框，然后通过一个或多个附加阶段细化候选框。第一阶段采用滑动窗口在给定尺度上提出候选边界框，后一阶段拒绝误报并细化剩余框。在这种情况下，级联架构[119193301314]自然是从粗到细人脸检测的有效解决方案。

​		单阶段方法。单阶段方法直接从特征图中完成候选分类和边界框回归，不依赖于建议阶段。单级的一种经典结构来自于一种名为single Shot multibox detector（SSD）的通用物体探测器[136]。它的运行速度比多级的要快得多，同时保持了相当的准确性。基于SSD，许多研究[98221321-323]开发了对不同尺度的人脸具有鲁棒性的深度人脸检测器。至于骨干架构，许多人脸检测器求助于特征金字塔网络（FPN）[127]，该网络由具有跳过连接的自上而下的架构组成，并合并高级和低级特征进行检测。高层次特征图提供了丰富的语义信息，而低层次特征图补充了更多的局部信息。特征融合保留了双方的优势，在检测宽尺度物体方面取得了巨大进展。虽然单级方法具有效率高的优点，但其检测精度低于两级方法。部分原因是密集锚带来的正负不平衡问题，而改进方案的建议能够缓解这一问题。因此，RefineDet[319]在其网络中设置了一个锚点细化模块，以去除大量否定。受RefineDet的启发，SRN[32]提出了一种选择性的两步分类和回归方法；在底层进行两步分类以减少分类器的搜索空间，在高层进行两步回归以获得准确的位置

​		由于开发时间长，性能优越，目前大多数人脸检测器都是基于锚点的。通常，我们在特征图上预设锚点，然后对这些锚点进行一次或多次分类和边界框回归，最后输出接受的锚点作为检测结果。因此，锚的分配和匹配策略对检测精度至关重要。

​		无锚方法[1161224346]在一般物体检测中引起了越来越多的关注。关于人脸检测，近年来出现了一些开创性的工作。DenseBox[89]和UnitBox[294]试图预测人脸上的像素边界框。CenterFace[279]将人脸检测视为一项广义的关键点估计任务，该任务预测人脸中心点和特征图中边界框的大小。简言之，无锚检测器摆脱了预设的锚，实现了更好的泛化能力。关于检测精度，需要进一步探索，以提高对误报的鲁棒性和训练过程的稳定性。

​		多任务学习方法。通常，多任务学习方法是为了通过共享视觉表示来与其他相关任务一起解决问题而设计的。在这里，我们介绍了多任务学习方法，这些方法将人脸检测器与相关的人脸任务或辅助监督分支一起训练，以丰富特征表示和检测鲁棒性。许多方法[27，89，124，279，305，314，355]已经探索了面部检测和面部地标定位的联合学习。其中，MTCNN[314]是最具代表性的一个，它利用了面部边界框和地标之间的固有相关性。随后，HyperFace[176]融合了低级特征和高级特征，同时进行了四项任务，包括人脸检测、面部地标定位、性别分类和姿态估计。基于RetinaNet[128]，RetinaFace[41]将人脸检测、面部地标定位和密集3D人脸回归集成在一个框架中。从多任务例程中，我们可以看到面部检测器可以从相关的面部任务中受益。此外，某些方法[931252241]利用辅助监督分支，如分割分支、无锚分支等。这些分支用于增强人脸检测的训练。
​    
#### 人脸对齐

​		接下来，人脸对齐是指将检测到的人脸校准到规范视图，并将其裁剪为标准化的像素大小，以便于后续的人脸表示计算任务。它是人脸识别系统的一个重要的中间过程。通常情况下，人脸地标定位是人脸对齐所必需的，而一些方法可以直接从输入的人脸中生成对齐的人脸。

​		由于人脸具有规则的结构，其中面部（眼睛、鼻子、嘴巴等）具有恒定的排列，因此人脸的对齐对后续人脸识别的特征计算有很大的好处。对于大多数现有的面部对齐方法，面部标志或所谓的面部关键点是必不可少的，因为它们作为相似性变换或仿射变换的参考。因此，人脸地标定位是人脸定位的前提。基于DCNN的人脸地标定位方法可分为三个子类：坐标回归、热图回归和基于三维模型拟合的方法。

#### 人脸表示

​		在人脸表示阶段，从对齐的人脸图像中提取判别特征进行识别。这是人脸识别的最后一步，也是核心步骤。在早期的研究中，许多方法通过将人脸图像投影到低维子空间来计算人脸表示，如特征面(PCA)和Fisherfaces。后来，手工制作的基于局部描述符的方法在这一领域盛行。

​		关于训练监督，我们主要介绍了四种方案，包括分类、特征嵌入、混合和半监督方案。


## 论文二：Unconstrained Face Recognition: Identifying a Person of Interest From a Media Collection

### 不理解概念
P2152: 秩的概念 ->> Rank

